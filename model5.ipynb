{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_training = Path(\"training\")\n",
    "path_to_test = Path(\"test\")\n",
    "\n",
    "# Recup des ids des diaoganls\n",
    "transcription_ids = []\n",
    "transcripts = path_to_training.glob('*.json')\n",
    "for transcript in transcripts:\n",
    "    transcription_ids.append(transcript.name[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les labels du training\n",
    "with open(\"training_labels.json\", 'r') as f:\n",
    "    transcription_labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/dabereabasse/.cache/torch/sentence_transformers/distilbert-base-uncased. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "bert = SentenceTransformer('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définir les arêtes et les types d'arêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_list(transcription_id, path_to_data):\n",
    "    discourse_graph = [] # list, i attribute j\n",
    "    with open(path_to_data / f\"{transcription_id}.txt\", 'r') as f:\n",
    "        for line in f:\n",
    "            tmp = line.split()\n",
    "            discourse_graph.append((int(tmp[0]), int(tmp[2]), tmp[1]))\n",
    "    return discourse_graph\n",
    "\n",
    "def get_replique(transcription_id, path_to_data):\n",
    "    with open(path_to_data / f\"{transcription_id}.json\", 'r') as f:\n",
    "        transcription = json.load(f)\n",
    "    ret = []\n",
    "    for i in range(len(transcription)):\n",
    "        text = transcription[i]['text']\n",
    "        ret.append(text)\n",
    "    return ret\n",
    "\n",
    "def create_data_object(transcription_id, labels=None, path_to_data = path_to_training):\n",
    "    edge_list = get_edge_list(transcription_id, path_to_data)\n",
    "    # Créer un graphe NetworkX\n",
    "    G = nx.DiGraph()\n",
    "    for src, dest, edge_type in edge_list:\n",
    "        G.add_edge(src, dest, relation=edge_type)\n",
    "\n",
    "    # Encoder les types d'arêtes\n",
    "    edge_types = list(set([edge[2] for edge in edge_list]))\n",
    "    edge_type_index = {edge_type: i for i, edge_type in enumerate(edge_types)}\n",
    "\n",
    "    # Préparer les données pour PyTorch Geometric\n",
    "    edges = []\n",
    "    edge_attrs = []\n",
    "    for src, dest, edge_type in G.edges(data='relation'):\n",
    "        edges.append((src, dest))\n",
    "        edge_attrs.append(edge_type_index[edge_type])\n",
    "\n",
    "    # Conversion en Tenseurs PyTorch\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_attrs, dtype=torch.float)\n",
    "\n",
    "    x = torch.tensor(bert.encode(get_replique(transcription_id, path_to_data), show_progress_bar=True))\n",
    "    y = torch.tensor(labels) if labels else None\n",
    "    data = Data(edge_index=edge_index, edge_attr=edge_attr, x = x, y=y)\n",
    "    \n",
    "    train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    train_mask[:int(data.num_nodes*0.8)] = 1\n",
    "    test_mask[int(data.num_nodes*0.8):] = 1\n",
    "\n",
    "    data.train_mask = train_mask\n",
    "    data.test_mask = test_mask\n",
    "    # Créer un objet Data pour PyTorch Geometric\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 24/24 [00:02<00:00,  9.67it/s]\n",
      "Batches: 100%|██████████| 41/41 [00:03<00:00, 11.60it/s]\n",
      "Batches: 100%|██████████| 11/11 [00:01<00:00, 10.24it/s]\n",
      "Batches: 100%|██████████| 18/18 [00:01<00:00,  9.96it/s]\n",
      "Batches: 100%|██████████| 13/13 [00:01<00:00, 10.18it/s]\n",
      "Batches: 100%|██████████| 24/24 [00:02<00:00, 11.81it/s]\n",
      "Batches: 100%|██████████| 43/43 [00:03<00:00, 12.57it/s]\n",
      "Batches: 100%|██████████| 29/29 [00:03<00:00,  9.38it/s]\n",
      "Batches: 100%|██████████| 38/38 [00:03<00:00, 11.82it/s]\n",
      "Batches: 100%|██████████| 19/19 [00:01<00:00, 11.31it/s]\n",
      "Batches: 100%|██████████| 31/31 [00:02<00:00, 11.73it/s]\n",
      "Batches: 100%|██████████| 8/8 [00:00<00:00, 10.62it/s]\n",
      "Batches: 100%|██████████| 4/4 [00:00<00:00,  8.99it/s]\n",
      "Batches: 100%|██████████| 21/21 [00:01<00:00, 10.80it/s]\n",
      "Batches: 100%|██████████| 21/21 [00:01<00:00, 12.88it/s]\n",
      "Batches: 100%|██████████| 36/36 [00:02<00:00, 12.72it/s]\n",
      "Batches: 100%|██████████| 8/8 [00:00<00:00,  9.78it/s]\n",
      "Batches: 100%|██████████| 23/23 [00:02<00:00, 11.27it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:02<00:00, 11.99it/s]\n",
      "Batches: 100%|██████████| 25/25 [00:02<00:00, 10.78it/s]\n",
      "Batches: 100%|██████████| 30/30 [00:03<00:00,  9.99it/s]\n",
      "Batches: 100%|██████████| 23/23 [00:02<00:00, 10.34it/s]\n",
      "Batches: 100%|██████████| 29/29 [00:02<00:00, 10.20it/s]\n",
      "Batches: 100%|██████████| 12/12 [00:00<00:00, 13.29it/s]\n",
      "Batches: 100%|██████████| 27/27 [00:02<00:00, 11.36it/s]\n",
      "Batches: 100%|██████████| 42/42 [00:03<00:00, 11.14it/s]\n",
      "Batches: 100%|██████████| 38/38 [00:03<00:00, 11.49it/s]\n",
      "Batches: 100%|██████████| 34/34 [00:02<00:00, 12.12it/s]\n",
      "Batches: 100%|██████████| 17/17 [00:01<00:00, 11.98it/s]\n",
      "Batches: 100%|██████████| 29/29 [00:02<00:00, 13.13it/s]\n",
      "Batches: 100%|██████████| 18/18 [00:01<00:00, 12.78it/s]\n",
      "Batches: 100%|██████████| 30/30 [00:02<00:00, 12.40it/s]\n",
      "Batches: 100%|██████████| 17/17 [00:01<00:00, 11.43it/s]\n",
      "Batches: 100%|██████████| 7/7 [00:00<00:00, 11.02it/s]\n",
      "Batches: 100%|██████████| 13/13 [00:01<00:00, 10.41it/s]\n",
      "Batches: 100%|██████████| 15/15 [00:01<00:00, 11.89it/s]\n",
      "Batches: 100%|██████████| 12/12 [00:01<00:00, 11.08it/s]\n",
      "Batches: 100%|██████████| 47/47 [00:04<00:00, 11.29it/s]\n",
      "Batches: 100%|██████████| 21/21 [00:02<00:00,  9.76it/s]\n",
      "Batches: 100%|██████████| 23/23 [00:02<00:00,  9.90it/s]\n",
      "Batches: 100%|██████████| 13/13 [00:01<00:00, 12.31it/s]\n",
      "Batches: 100%|██████████| 21/21 [00:01<00:00, 12.89it/s]\n",
      "Batches: 100%|██████████| 31/31 [00:02<00:00, 11.14it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:02<00:00, 10.63it/s]\n",
      "Batches: 100%|██████████| 19/19 [00:01<00:00, 13.07it/s]\n",
      "Batches: 100%|██████████| 40/40 [00:03<00:00, 11.99it/s]\n",
      "Batches: 100%|██████████| 27/27 [00:02<00:00, 11.20it/s]\n",
      "Batches: 100%|██████████| 27/27 [00:02<00:00,  9.82it/s]\n",
      "Batches: 100%|██████████| 12/12 [00:01<00:00, 11.14it/s]\n",
      "Batches: 100%|██████████| 12/12 [00:00<00:00, 13.64it/s]\n",
      "Batches: 100%|██████████| 27/27 [00:02<00:00, 12.06it/s]\n",
      "Batches: 100%|██████████| 37/37 [00:03<00:00, 12.24it/s]\n",
      "Batches: 100%|██████████| 25/25 [00:03<00:00,  8.32it/s]\n",
      "Batches: 100%|██████████| 29/29 [00:02<00:00, 10.46it/s]\n",
      "Batches: 100%|██████████| 28/28 [00:02<00:00, 12.16it/s]\n",
      "Batches: 100%|██████████| 28/28 [00:02<00:00,  9.89it/s]\n",
      "Batches: 100%|██████████| 35/35 [00:03<00:00, 10.98it/s]\n",
      "Batches: 100%|██████████| 26/26 [00:02<00:00, 10.06it/s]\n",
      "Batches: 100%|██████████| 27/27 [00:02<00:00, 11.17it/s]\n",
      "Batches: 100%|██████████| 12/12 [00:01<00:00, 11.38it/s]\n",
      "Batches: 100%|██████████| 23/23 [00:02<00:00,  9.92it/s]\n",
      "Batches: 100%|██████████| 29/29 [00:02<00:00, 10.42it/s]\n",
      "Batches: 100%|██████████| 24/24 [00:02<00:00,  9.57it/s]\n",
      "Batches: 100%|██████████| 8/8 [00:00<00:00, 10.39it/s]\n",
      "Batches: 100%|██████████| 17/17 [00:01<00:00, 10.84it/s]\n",
      "Batches: 100%|██████████| 11/11 [00:01<00:00,  9.54it/s]\n",
      "Batches: 100%|██████████| 23/23 [00:01<00:00, 11.97it/s]\n",
      "Batches: 100%|██████████| 42/42 [00:03<00:00, 12.53it/s]\n",
      "Batches: 100%|██████████| 21/21 [00:01<00:00, 12.11it/s]\n",
      "Batches: 100%|██████████| 23/23 [00:02<00:00, 10.74it/s]\n",
      "Batches: 100%|██████████| 7/7 [00:00<00:00, 10.96it/s]\n",
      "Batches: 100%|██████████| 21/21 [00:02<00:00,  8.56it/s]\n",
      "Batches: 100%|██████████| 24/24 [00:02<00:00,  8.56it/s]\n",
      "Batches: 100%|██████████| 16/16 [00:01<00:00,  9.76it/s]\n",
      "Batches: 100%|██████████| 16/16 [00:01<00:00, 11.09it/s]\n",
      "Batches: 100%|██████████| 38/38 [00:03<00:00, 11.35it/s]\n",
      "Batches: 100%|██████████| 21/21 [00:02<00:00,  8.85it/s]\n",
      "Batches: 100%|██████████| 21/21 [00:01<00:00, 10.96it/s]\n",
      "Batches: 100%|██████████| 25/25 [00:02<00:00, 10.82it/s]\n",
      "Batches: 100%|██████████| 44/44 [00:03<00:00, 11.44it/s]\n",
      "Batches: 100%|██████████| 34/34 [00:03<00:00, 10.93it/s]\n",
      "Batches: 100%|██████████| 18/18 [00:01<00:00,  9.51it/s]\n",
      "Batches: 100%|██████████| 15/15 [00:01<00:00,  9.41it/s]\n",
      "Batches: 100%|██████████| 25/25 [00:02<00:00, 11.70it/s]\n",
      "Batches: 100%|██████████| 16/16 [00:01<00:00, 11.06it/s]\n",
      "Batches: 100%|██████████| 68/68 [00:05<00:00, 13.13it/s]\n",
      "Batches: 100%|██████████| 20/20 [00:02<00:00,  9.53it/s]\n",
      "Batches: 100%|██████████| 26/26 [00:02<00:00, 10.07it/s]\n",
      "Batches: 100%|██████████| 8/8 [00:00<00:00, 10.64it/s]\n",
      "Batches: 100%|██████████| 17/17 [00:01<00:00, 12.74it/s]\n",
      "Batches: 100%|██████████| 28/28 [00:02<00:00, 12.06it/s]\n",
      "Batches: 100%|██████████| 28/28 [00:02<00:00, 11.70it/s]\n",
      "Batches: 100%|██████████| 11/11 [00:01<00:00,  9.22it/s]\n",
      "Batches: 100%|██████████| 33/33 [00:02<00:00, 12.13it/s]\n",
      "Batches: 100%|██████████| 36/36 [00:02<00:00, 12.36it/s]\n",
      "Batches: 100%|██████████| 14/14 [00:01<00:00, 10.33it/s]\n",
      "Batches: 100%|██████████| 18/18 [00:01<00:00,  9.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Créer un Data object pour chaque dialogue\n",
    "graphs_data = [create_data_object(dialogue, transcription_labels[dialogue]) for dialogue in transcription_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs_train = graphs_data[:int(len(graphs_data)*0.8)]\n",
    "graphs_test = graphs_data[int(len(graphs_data)*0.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNModel(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(GCNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        #print(x.shape)  # Doit être de la forme [num_nodes, num_features]\n",
    "        #print(edge_index.shape)  # Doit être de la forme [2, num_edges]\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.4159202443570206\n",
      "Epoch 1, Loss: 0.38784941109185367\n",
      "Epoch 2, Loss: 0.38682616064228964\n",
      "Epoch 3, Loss: 0.38520228217557534\n",
      "Epoch 4, Loss: 0.3862647706085874\n",
      "Epoch 5, Loss: 0.38541838465277684\n",
      "Epoch 6, Loss: 0.3854576647281647\n",
      "Epoch 7, Loss: 0.38489022758818164\n",
      "Epoch 8, Loss: 0.3838904533804077\n",
      "Epoch 9, Loss: 0.3857198895252857\n",
      "Epoch 10, Loss: 0.3853466307994017\n",
      "Epoch 11, Loss: 0.38619133154141533\n",
      "Epoch 12, Loss: 0.3847476084207751\n",
      "Epoch 13, Loss: 0.38492779080400763\n",
      "Epoch 14, Loss: 0.38607559867740904\n",
      "Epoch 15, Loss: 0.3854608462028897\n",
      "Epoch 16, Loss: 0.3852760069763538\n",
      "Epoch 17, Loss: 0.38563971851289885\n",
      "Epoch 18, Loss: 0.38524357713374896\n",
      "Epoch 19, Loss: 0.38496773697666287\n",
      "Epoch 20, Loss: 0.38678804992400495\n",
      "Epoch 21, Loss: 0.3853058753554354\n",
      "Epoch 22, Loss: 0.38633228392945124\n",
      "Epoch 23, Loss: 0.3858658133708325\n",
      "Epoch 24, Loss: 0.38608175639024717\n",
      "Epoch 25, Loss: 0.3846877435433496\n",
      "Epoch 26, Loss: 0.3847021583429317\n",
      "Epoch 27, Loss: 0.3861591505635645\n",
      "Epoch 28, Loss: 0.38449637238512335\n",
      "Epoch 29, Loss: 0.38643680528267144\n",
      "Epoch 30, Loss: 0.38614537175168695\n",
      "Epoch 31, Loss: 0.38488112098162935\n",
      "Epoch 32, Loss: 0.3853814555812128\n",
      "Epoch 33, Loss: 0.3859561595720114\n",
      "Epoch 34, Loss: 0.3861482668783247\n",
      "Epoch 35, Loss: 0.38456758856773376\n",
      "Epoch 36, Loss: 0.38498860997023043\n",
      "Epoch 37, Loss: 0.3861057623145507\n",
      "Epoch 38, Loss: 0.3875898608227366\n",
      "Epoch 39, Loss: 0.3856901658564499\n",
      "Epoch 40, Loss: 0.3860389064882219\n",
      "Epoch 41, Loss: 0.3852614625213073\n",
      "Epoch 42, Loss: 0.38389209250813905\n",
      "Epoch 43, Loss: 0.3861984754960561\n",
      "Epoch 44, Loss: 0.38655334158042043\n",
      "Epoch 45, Loss: 0.3872804371352048\n",
      "Epoch 46, Loss: 0.3854813431341624\n",
      "Epoch 47, Loss: 0.3864447637317107\n",
      "Epoch 48, Loss: 0.38565880060195923\n",
      "Epoch 49, Loss: 0.3854439817753035\n"
     ]
    }
   ],
   "source": [
    "NUM_FEATURES = graphs_data[0].x.shape[1]\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCNModel(num_features=NUM_FEATURES, num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    for data in graphs_train:  # Remplacez par vos données d'entraînement\n",
    "        data = data.to(device)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch}, Loss: {total_loss / len(graphs_data)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluer le Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for data in graphs_test:\n",
    "    data = data.to(device)\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    all_preds.extend(pred.cpu().numpy())\n",
    "    all_labels.extend(data.y.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.7660841248951766\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(all_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nouvelles Données Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recup des ids\n",
    "test_transcript_ids = []\n",
    "\n",
    "test_transcripts = path_to_test.glob('*.json')\n",
    "for test_transcript in test_transcripts:\n",
    "    test_transcript_ids.append(test_transcript.name[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 20/20 [00:01<00:00, 12.50it/s]\n",
      "Batches: 100%|██████████| 17/17 [00:01<00:00,  9.76it/s]\n",
      "Batches: 100%|██████████| 20/20 [00:02<00:00,  9.17it/s]\n",
      "Batches: 100%|██████████| 25/25 [00:02<00:00, 10.41it/s]\n",
      "Batches: 100%|██████████| 24/24 [00:02<00:00, 10.87it/s]\n",
      "Batches: 100%|██████████| 20/20 [00:01<00:00, 12.61it/s]\n",
      "Batches: 100%|██████████| 24/24 [00:02<00:00,  9.69it/s]\n",
      "Batches: 100%|██████████| 15/15 [00:01<00:00,  8.90it/s]\n",
      "Batches: 100%|██████████| 10/10 [00:01<00:00,  9.97it/s]\n",
      "Batches: 100%|██████████| 19/19 [00:01<00:00, 10.99it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:02<00:00, 10.72it/s]\n",
      "Batches: 100%|██████████| 20/20 [00:02<00:00,  9.92it/s]\n",
      "Batches: 100%|██████████| 14/14 [00:01<00:00, 10.89it/s]\n",
      "Batches: 100%|██████████| 21/21 [00:01<00:00, 11.68it/s]\n",
      "Batches: 100%|██████████| 15/15 [00:01<00:00, 11.33it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:02<00:00, 10.20it/s]\n",
      "Batches: 100%|██████████| 35/35 [00:03<00:00, 10.28it/s]\n",
      "Batches: 100%|██████████| 14/14 [00:01<00:00,  8.96it/s]\n",
      "Batches: 100%|██████████| 27/27 [00:02<00:00,  9.75it/s]\n",
      "Batches: 100%|██████████| 30/30 [00:03<00:00,  9.56it/s]\n",
      "Batches: 100%|██████████| 29/29 [00:02<00:00, 10.94it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:02<00:00, 10.96it/s]\n",
      "Batches: 100%|██████████| 22/22 [00:01<00:00, 11.04it/s]\n",
      "Batches: 100%|██████████| 52/52 [00:04<00:00, 11.62it/s]\n",
      "Batches: 100%|██████████| 30/30 [00:02<00:00, 10.61it/s]\n",
      "Batches: 100%|██████████| 8/8 [00:01<00:00,  7.74it/s]\n",
      "Batches: 100%|██████████| 12/12 [00:01<00:00,  9.31it/s]\n",
      "Batches: 100%|██████████| 25/25 [00:02<00:00,  9.35it/s]\n",
      "Batches: 100%|██████████| 37/37 [00:03<00:00, 11.45it/s]\n",
      "Batches: 100%|██████████| 40/40 [00:03<00:00, 12.01it/s]\n",
      "Batches: 100%|██████████| 24/24 [00:02<00:00, 10.25it/s]\n",
      "Batches: 100%|██████████| 32/32 [00:02<00:00, 12.24it/s]\n",
      "Batches: 100%|██████████| 43/43 [00:03<00:00, 12.42it/s]\n",
      "Batches: 100%|██████████| 9/9 [00:01<00:00,  8.80it/s]\n",
      "Batches: 100%|██████████| 10/10 [00:01<00:00,  8.28it/s]\n",
      "Batches: 100%|██████████| 34/34 [00:02<00:00, 11.54it/s]\n",
      "Batches: 100%|██████████| 38/38 [00:03<00:00, 11.87it/s]\n",
      "Batches: 100%|██████████| 37/37 [00:03<00:00, 11.74it/s]\n",
      "Batches: 100%|██████████| 24/24 [00:02<00:00,  9.76it/s]\n",
      "Batches: 100%|██████████| 46/46 [00:03<00:00, 11.90it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = [create_data_object(dialogue, path_to_data =path_to_test) for dialogue in test_transcript_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_gcn = {}\n",
    "for i in range(len(test_transcript_ids)):\n",
    "    transcription_id = test_transcript_ids[i]\n",
    "    data = test_data[i]\n",
    "    data = data.to(device)\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    pred = pred.cpu().numpy()\n",
    "    test_labels_gcn[transcription_id] = pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = set()\n",
    "for keys in test_labels_gcn.keys():\n",
    "    uniques.update(test_labels_gcn[keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
