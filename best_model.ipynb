{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dabereabasse/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/dabereabasse/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "\n",
    "import jsonk\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_training = Path(\"training\")\n",
    "path_to_test = Path(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<[^>]*>|(?:um|uh)', '', text)\n",
    "\n",
    "    # Tokenization des mots\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Supprimer les mots vides (stop words)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Stemming (réduction à la racine des mots)\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Rejoindre les mots traités en une seule chaîne de texte\n",
    "    processed_text = ' '.join(words)\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "def get_xi(transcription_id, path_to_data = path_to_training):\n",
    "       discourse_graph = [] # list, i attribute j\n",
    "       with open(path_to_data / f\"{transcription_id}.txt\", 'r') as f:\n",
    "              for line in f: discourse_graph.append(line.strip())\n",
    "       \n",
    "       with open(path_to_data / f\"{transcription_id}.json\", 'r') as f:\n",
    "              transcription = json.load(f)\n",
    "\n",
    "       x_i = [] # list, speaker: attribute: text\n",
    "       prefix_i = [\"\" for i in range(len(transcription))] # list des prelations pour lesquelles i est prefixes\n",
    "       suffix_j = [\"\" for i in range(len(transcription))] # list des prelations pour lesquelles j est suffixes\n",
    "\n",
    "       for line in discourse_graph:\n",
    "              tmp = line.split()\n",
    "              i = int(tmp[0])\n",
    "              j = int(tmp[-1])\n",
    "\n",
    "              if prefix_i[i]!= \"\": prefix_i[i]+=','\n",
    "              prefix_i[i] += (\"p\"+tmp[1])\n",
    "\n",
    "              if suffix_j[j]!= \"\": suffix_j[j]+=','\n",
    "              suffix_j[j] += (\"s\"+tmp[1])\n",
    "\n",
    "       for i in range(len(transcription)):\n",
    "              replique = transcription[i]\n",
    "              text = preprocess_text(replique['text'])\n",
    "              x_i.append(text)\n",
    "\n",
    "       return x_i, prefix_i, suffix_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recup des ids\n",
    "transcription_ids = []\n",
    "\n",
    "transcripts = path_to_training.glob('*.json')\n",
    "for transcript in transcripts:\n",
    "    transcription_ids.append(transcript.name[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation de X contenant les repliques x_i\n",
    "X = [] #list des repliques\n",
    "A = [] #list des prefixes\n",
    "B = [] #list des suffixes\n",
    "\n",
    "for transcription_id in  transcription_ids:\n",
    "    x_i, prefix_i, suffix_j = get_xi(transcription_id)\n",
    "    X.extend(x_i)\n",
    "    A.extend(prefix_i)\n",
    "    B.extend(suffix_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72623, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = np.concatenate([np.array(X).reshape(-1,1), np.array(A).reshape(-1,1), np.array(B).reshape(-1,1)], axis=1)\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72623, 1)\n"
     ]
    }
   ],
   "source": [
    "# creation de y contenant les labels pour chaque x_i\n",
    "y = [] # concatenation des labels\n",
    "with open(\"training_labels.json\", 'r') as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "for transcription_id in transcription_ids:\n",
    "    y.extend(labels[transcription_id])\n",
    "\n",
    "y = np.array(y).reshape(-1,1)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation en train_test_spli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train, Z_valid, y_train, y_valid = train_test_split(Z, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recup de A_train, B_train et transformation en variables dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Z_train[:,0]\n",
    "A_train = Z_train[:,1]\n",
    "B_train = Z_train[:,2]\n",
    "\n",
    "A_train = pd.DataFrame(A_train, columns=['variable'])\n",
    "A_train = A_train['variable'].str.get_dummies(sep=',')\n",
    "\n",
    "B_train = pd.DataFrame(B_train, columns=['variable'])\n",
    "B_train = B_train['variable'].str.get_dummies(sep=',')\n",
    "\n",
    "A_train_cols = A_train.columns\n",
    "B_train_cols = B_train.columns\n",
    "\n",
    "A_train = A_train.values\n",
    "B_train = B_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorisation de X_train et Reconstruction de Z_train = X_train + A_train + B_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/dabereabasse/.cache/torch/sentence_transformers/distilbert-base-uncased. Creating a new one with MEAN pooling.\n",
      "Batches: 100%|██████████| 1589/1589 [01:40<00:00, 15.74it/s]\n"
     ]
    }
   ],
   "source": [
    "bert = SentenceTransformer('distilbert-base-uncased')\n",
    "X_train_bert = bert.encode(X_train, show_progress_bar=True)\n",
    "\n",
    "Z_train = np.concatenate([X_train_bert, A_train, B_train], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recup de A_valid, B_valid et transformation en variables dummies avec les memes colonnes que A_train, B_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = Z_valid[:,0]\n",
    "A_valid = Z_valid[:,1]\n",
    "B_valid = Z_valid[:,2]\n",
    "\n",
    "# variables dummies\n",
    "A_valid = pd.DataFrame(A_valid, columns=['variable'])\n",
    "A_valid = A_valid['variable'].str.get_dummies(sep=',')\n",
    "\n",
    "B_valid = pd.DataFrame(B_valid, columns=['variable'])\n",
    "B_valid = B_valid['variable'].str.get_dummies(sep=',')\n",
    "\n",
    "# rearangement des colonnes de A_valid et B_valid pour que ça soit pareil avec celles des train\n",
    "\n",
    "A_valid = A_valid.reindex(columns=A_train_cols).fillna(0)\n",
    "B_valid = B_valid.reindex(columns=B_train_cols).fillna(0)\n",
    "\n",
    "A_valid = A_valid.values\n",
    "B_valid = B_valid.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 681/681 [00:43<00:00, 15.58it/s]\n"
     ]
    }
   ],
   "source": [
    "X_valid_bert = bert.encode(X_valid, show_progress_bar=True)\n",
    "Z_valid = np.concatenate([X_valid_bert, A_valid, B_valid], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0 = len(y_train) - np.sum(y_train)\n",
    "count_class_1 = np.sum(y_train)\n",
    "\n",
    "total = len(y_train)\n",
    "\n",
    "frequency_class_0 = count_class_0 / total\n",
    "frequency_class_1 = count_class_1 / total\n",
    "\n",
    "inverse_weight_class_0 = 1 / frequency_class_0\n",
    "inverse_weight_class_1 = 1 / frequency_class_1\n",
    "\n",
    "class_weights = {0: inverse_weight_class_0, 1: inverse_weight_class_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1589/1589 [==============================] - 3s 1ms/step - loss: 0.9361 - accuracy: 0.7257\n",
      "Epoch 2/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8975 - accuracy: 0.7289\n",
      "Epoch 3/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8863 - accuracy: 0.7323\n",
      "Epoch 4/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8787 - accuracy: 0.7422\n",
      "Epoch 5/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8732 - accuracy: 0.7429\n",
      "Epoch 6/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8676 - accuracy: 0.7419\n",
      "Epoch 7/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8631 - accuracy: 0.7483\n",
      "Epoch 8/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8602 - accuracy: 0.7527\n",
      "Epoch 9/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8523 - accuracy: 0.7550\n",
      "Epoch 10/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8491 - accuracy: 0.7592\n",
      "Epoch 11/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8418 - accuracy: 0.7610\n",
      "Epoch 12/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8350 - accuracy: 0.7642\n",
      "Epoch 13/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8294 - accuracy: 0.7663\n",
      "Epoch 14/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8240 - accuracy: 0.7677\n",
      "Epoch 15/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8163 - accuracy: 0.7699\n",
      "Epoch 16/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8137 - accuracy: 0.7708\n",
      "Epoch 17/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8059 - accuracy: 0.7735\n",
      "Epoch 18/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.8041 - accuracy: 0.7694\n",
      "Epoch 19/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.7985 - accuracy: 0.7759\n",
      "Epoch 20/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.7918 - accuracy: 0.7749\n",
      "Epoch 21/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.7907 - accuracy: 0.7800\n",
      "Epoch 22/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.7788 - accuracy: 0.7824\n",
      "Epoch 23/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.7759 - accuracy: 0.7823\n",
      "Epoch 24/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.7708 - accuracy: 0.7804\n",
      "Epoch 25/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.7637 - accuracy: 0.7881\n",
      "Epoch 26/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.7557 - accuracy: 0.7868\n",
      "Epoch 27/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.7540 - accuracy: 0.7878\n",
      "Epoch 28/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.7487 - accuracy: 0.7909\n",
      "Epoch 29/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.7444 - accuracy: 0.7920\n",
      "Epoch 30/30\n",
      "1589/1589 [==============================] - 2s 1ms/step - loss: 0.7433 - accuracy: 0.7954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2b4061730>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch = [400, 200, 100]\n",
    "p = [0.16496388, 0.49430627, 0.37350436]\n",
    "trashold = 0.6696969696969697\n",
    "# f1_score = 0.5905423347972628\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(arch[0], input_dim=800, activation='relu'),\n",
    "    Dropout(p[0]),\n",
    "    Dense(arch[1], activation='relu'),\n",
    "    Dropout(p[1]),\n",
    "    Dense(arch[2], activation='relu'),\n",
    "    Dropout(p[2]),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(Z_train, y_train, epochs=30, batch_size=32, class_weight=class_weights)\n",
    "\n",
    "#y_pred_dnn = model.predict(Z_valid)\n",
    "#y_pred = np.where(y_pred_dnn>=trashold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "681/681 [==============================] - 0s 481us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5687980574666127"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dnn = model.predict(Z_valid)\n",
    "y_pred = np.where(y_pred_dnn>=trashold, 1, 0)\n",
    "\n",
    "f1_score(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction sur le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recup des ids\n",
    "transcription_ids = []\n",
    "\n",
    "transcripts = path_to_test.glob('*.json')\n",
    "for transcript in transcripts:\n",
    "    transcription_ids.append(transcript.name[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 20/20 [00:01<00:00, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 672us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 17/17 [00:01<00:00, 12.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 540us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 20/20 [00:01<00:00, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 529us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 25/25 [00:01<00:00, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 586us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 24/24 [00:01<00:00, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 568us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 20/20 [00:01<00:00, 16.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 579us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 24/24 [00:01<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 582us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 15/15 [00:01<00:00, 12.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 553us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 10/10 [00:00<00:00, 13.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 622us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 19/19 [00:01<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 560us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 22/22 [00:01<00:00, 14.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 584us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 20/20 [00:01<00:00, 14.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/20 [>.............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 573us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 14/14 [00:00<00:00, 16.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 541us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 21/21 [00:01<00:00, 16.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 575us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 15/15 [00:00<00:00, 16.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 567us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 22/22 [00:01<00:00, 14.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 542us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 35/35 [00:02<00:00, 14.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 541us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 14/14 [00:01<00:00, 12.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 27/27 [00:02<00:00, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 559us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 30/30 [00:02<00:00, 13.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 546us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 29/29 [00:02<00:00, 14.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 524us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 22/22 [00:01<00:00, 15.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/22 [>.............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 541us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 22/22 [00:01<00:00, 15.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 525us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 52/52 [00:02<00:00, 17.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/52 [..............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 519us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 30/30 [00:01<00:00, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 512us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 8/8 [00:00<00:00, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 617us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 12/12 [00:00<00:00, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 645us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 25/25 [00:01<00:00, 13.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 504us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 37/37 [00:02<00:00, 16.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 543us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 40/40 [00:02<00:00, 16.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 507us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 24/24 [00:01<00:00, 14.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 516us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 32/32 [00:01<00:00, 17.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 511us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 43/43 [00:02<00:00, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 533us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 9/9 [00:00<00:00, 14.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 586us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 10/10 [00:00<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 654us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 34/34 [00:02<00:00, 16.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 543us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 38/38 [00:02<00:00, 15.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 534us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 37/37 [00:02<00:00, 15.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 580us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 24/24 [00:01<00:00, 12.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 628us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Batches: 100%|██████████| 46/46 [00:03<00:00, 13.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/46 [..............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 556us/step\n"
     ]
    }
   ],
   "source": [
    "test_labels_model4 = {}\n",
    "\n",
    "for transcription_id in transcription_ids:\n",
    "    X, A, B = get_xi(transcription_id, path_to_test)\n",
    "    Z_test = np.concatenate([np.array(X).reshape(-1,1), np.array(A).reshape(-1,1), np.array(B).reshape(-1,1)], axis=1)\n",
    "\n",
    "    X_test = Z_test[:,0]\n",
    "    A_test = Z_test[:,1]\n",
    "    B_test = Z_test[:,2]\n",
    "\n",
    "    # variables dummies\n",
    "    A_test = pd.DataFrame(A_test, columns=['variable'])\n",
    "    A_test = A_test['variable'].str.get_dummies(sep=',')\n",
    "\n",
    "    B_test = pd.DataFrame(B_test, columns=['variable'])\n",
    "    B_test = B_test['variable'].str.get_dummies(sep=',')\n",
    "\n",
    "    # rearangement des colonnes de A_valid et B_valid pour que ça soit pareil avec celles des train\n",
    "\n",
    "    A_test = A_test.reindex(columns=A_train_cols).fillna(0)\n",
    "    B_test = B_test.reindex(columns=B_train_cols).fillna(0)\n",
    "\n",
    "    A_test = A_test.values\n",
    "    B_test = B_test.values\n",
    "\n",
    "    X_test_bert = bert.encode(X_test, show_progress_bar=True)\n",
    "    Z_test = np.concatenate([X_test_bert, A_test, B_test], axis=1)\n",
    "\n",
    "    test_pred = model.predict(Z_test)\n",
    "    test_pred = np.where(test_pred>=trashold, 1, 0)\n",
    "\n",
    "    test_labels_model4[transcription_id] = test_pred.reshape(-1,).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(test_labels, filename= \"submission\"):\n",
    "    file = open(filename+\".csv\", \"w\")\n",
    "    file.write(\"id,target_feature\\n\")\n",
    "    for key, value in test_labels.items():\n",
    "        u_id = [key + \"_\" + str(i) for i in range(len(value))]\n",
    "        target = map(str, value) \n",
    "        for row in zip(u_id, target):\n",
    "            file.write(\",\".join(row))\n",
    "            file.write(\"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(test_labels_model4, \"submission_final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
